import requests
from PIL import Image
import io
import sys, os
from urllib.parse import quote
import base64
import streamlit as st
import speech_recognition as sr
from dotenv import load_dotenv

# Add the parent directory of 'text_to_image' (which is 'utils') to sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from imgur_uploader import ImgurUploader
# from pollinations_generator import PollinationsGenerator  # Circular import - commented out
# from together_ai_generator import TogetherAIGenerator  # File doesn't exist - commented out

# https://pollinations.ai/
## Parameters
# - prompt (required): The text description of the image you want to generate. Should be URL-encoded.
# - model (optional): The model to use for generation. Options: 'flux' or 'turbo'. Default: 'turbo'
# - seed (optional): Seed for reproducible results. Default: random
# - width (optional): Width of the generated image. Default: 1024
# - height (optional): Height of the generated image. Default: 1024
# - nologo (optional): Set to 'true' to turn off the rendering of the logo
# - nofeed (optional): Set to 'true' to prevent the image from appearing in the public feed
# - enhance (optional): Set to 'true' or 'false' to turn on or off prompt enhancing (passes prompts through an LLM to add detail)

## Example Usage
# https://image.pollinations.ai/prompt/A%20beautiful%20sunset%20over%20the%20ocean?model=flux&width=1280&height=720&seed=42&nologo=true&enhance=true

## Response
# The API returns a raw image file (typically JPEG or PNG) as the response body. You can directly embed the image in your HTML or Markdown.
class PollinationsGenerator:
    def __init__(self):
        self.pollinations_url = "https://image.pollinations.ai/prompt/{prompt}?model={model}&width=1280&height=720&seed=42&nologo=true&enhance=true"

    def generate_image(self, prompt, model_name, negative_prompt=None):
        encoded_prompt = quote(prompt)
        url = self.pollinations_url.format(prompt=encoded_prompt, model=model_name)
        
        if negative_prompt:
            url += f"&negative_prompt={quote(negative_prompt)}"
        
        try:
            uploader = ImgurUploader()
            base64_image = self.convert_image_url_to_base64(url)
            if base64_image:
                image_url = uploader.upload_media_to_imgur(
                     base64_image, 
                     "image",
                     model_name,  # Title
                     prompt  # Description
                )
                return image_url
            else:
                print("Failed to convert image to base64")
                return None 
        except requests.exceptions.RequestException as e:
            print(f"Error generating image with Pollinations: {e}")
            return None    

    @staticmethod
    def convert_image_url_to_base64(image_url):
        try:
            response = requests.get(image_url)
            response.raise_for_status()
            img = Image.open(io.BytesIO(response.content))
            buffered = io.BytesIO()
            img.save(buffered, format=img.format)
            image_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
            return image_base64
        except Exception as e:
            print(f"Failed to convert image from URL: {image_url}")
            print(f"Error: {str(e)}")
            return None

def test(upload_dir="uploads", model_name="turbo", filename=None):    
    generator = PollinationsGenerator()
    prompt = "A fast red color car"
    negative_prompt = "low quality, worst quality"
    
    if not os.path.exists(upload_dir):
        os.makedirs(upload_dir)

    image_url = generator.generate_image(prompt, model_name, negative_prompt)
    return image_url

if __name__ == "__main__":
    test_result = test("uploads", "turbo", "pollinations_generator.png")
    print(f"Test {'passed' if test_result else 'failed'}")   

# ×“×•×’×××•×ª ××•×›× ×•×ª
EXAMPLES = [
    "×× ×’×•, ×’×‘×™× ×ª ×¢×™×–×™×, ×“×‘×©, ××”×‘×”",
    "×¢× ×‘×™×, ×ª×× ×™×, ×¨×™××•× ×™×, ×©××—×”",
    "×¢×•×’×ª ×’×‘×™× ×”, ×¤×¨×—×™×, ×—×™×˜×”, ×©×•×§×•×œ×“",
    "×ª××¨×™×, ×™×™×Ÿ, ×’×‘×™× ×” ×¦×¤×ª×™×ª, ×—×™×•×š",
    "××‘×˜×™×—, ×œ×—×, ×©××Ÿ ×–×™×ª, ×‘×¨×›×”"
]

def transcribe_audio():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        st.info("ğŸ¤ ×”×§×œ×˜×” ××ª×—×™×œ×”...")
        audio = r.listen(source)
        st.info("ğŸµ ××¢×‘×“ ××ª ×”×”×§×œ×˜×”...")
    try:
        text = r.recognize_google(audio, language="he-IL")
        return text
    except sr.UnknownValueError:
        st.error("×œ× ×”×¦×œ×—×ª×™ ×œ×”×‘×™×Ÿ ××ª ×”×”×§×œ×˜×”")
        return None
    except sr.RequestError:
        st.error("×©×’×™××” ×‘×©×™×¨×•×ª ×”×”×§×œ×˜×”")
        return None

def generate_image(prompt):
    basket_prompt = (
        f"A beautiful Shavuot basket on a festive table, containing: {prompt}. "
        "The basket is overflowing with fresh, colorful produce, cheeses, and flowers. "
        "Ultra-realistic, vibrant, joyful, high detail, 4k, cinematic lighting."
    )
    return pollinations.generate_image(basket_prompt, "flux")

def generate_hebrew_text(prompt):
    # Simple placeholder since TogetherAIGenerator is not available
    return f"×¡×œ ×‘×™×›×•×¨×™× ××§×¡×™× ×¢× {prompt} - ××•×›×Ÿ ×œ×—×’ ×©×‘×•×¢×•×ª!"

def main():
    st.set_page_config(
        page_title="××” ×ª×‘×™× ×œ×‘×™×›×•×¨×™×? ğŸ‰",
        page_icon="ğŸ‰",
        layout="centered"
    )

    # ×¢×™×¦×•×‘ ×•×•××• + RTL
    st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Varela+Round&display=swap');
        .stApp { background: linear-gradient(135deg, #fffbe7 0%, #ffe5ec 100%); font-family: 'Varela Round', sans-serif; direction: rtl; }
        .wow-box { border-radius: 24px; box-shadow: 0 4px 32px #ffb6b6; border: 3px solid #ffb6b6; padding: 24px; background: #fff8; direction: rtl; text-align: right;}
        .example-btn { background: #fffbe7; border: 2px solid #ffb6b6; border-radius: 16px; margin: 4px; font-size: 1.1em; transition: 0.2s; }
        .example-btn:hover { background: #ffe5ec; color: #d72660; transform: scale(1.05);}
        .result-img { border-radius: 18px; box-shadow: 0 2px 16px #d7266060; border: 2px solid #d72660; }
        .circle-btn { width: 70px; height: 70px; border-radius: 50%; display: inline-flex; align-items: center; justify-content: center; font-size: 2.2em; margin: 0 12px; border: none; box-shadow: 0 2px 12px #d7266040; cursor: pointer; transition: 0.2s; }
        .mic-btn { background: linear-gradient(135deg, #ffb6b6 0%, #ff8c8c 100%); color: white; }
        .text-btn { background: linear-gradient(135deg, #5ec6ff 0%, #3a8dde 100%); color: white; }
        .circle-btn:hover { transform: scale(1.08);}
        .input-box { width: 100%; font-size: 1.1em; border-radius: 12px; border: 2px solid #ffb6b6; padding: 10px; margin-bottom: 10px; direction: rtl; text-align: right;}
        </style>
    """, unsafe_allow_html=True)

    st.markdown("<h2 style='text-align:center; color:#222;'>×¡×¤×¨×• ×œ× ×• ××” ×ª×¨×¦×• ×œ×”×‘×™× ×œ×¡×œ ×”×‘×™×›×•×¨×™× ×©×œ×›×</h2>", unsafe_allow_html=True)

    # ×›×¤×ª×•×¨×™ ×”×§×œ×˜×”/×”×§×œ×“×”
    st.markdown("""
    <div style='text-align:center; margin: 20px 0;'>
        <button class="circle-btn text-btn" id="text-btn" title="×”×§×œ×“×”">&#9993;</button>
        <button class="circle-btn mic-btn" id="mic-btn" title="×”×§×œ×˜×”">&#127908;</button>
    </div>
    <div style='text-align:center; color:#888; font-size:1em;'>×œ×—×¦×• ×¢×œ ×”××™×§×¨×•×¤×•×Ÿ ×œ×“×™×‘×•×¨ | ×œ×—×¦×• ×¢×œ ×”××¢×˜×¤×” ×œ×”×§×œ×“×”</div>
    """, unsafe_allow_html=True)

    # ×“×•×’×××•×ª ×œ×‘×—×™×¨×”
    st.markdown("<div style='text-align:center; margin-top:18px;'>", unsafe_allow_html=True)
    cols = st.columns(len(EXAMPLES))
    example_clicked = None
    for i, example in enumerate(EXAMPLES):
        if cols[i].button(example, key=f"ex_{i}"):
            example_clicked = example
    st.markdown("</div>", unsafe_allow_html=True)

    # --- ×œ×•×’×™×§×ª ×§×œ×˜ ---
    user_input = None
    # ×©×œ×™×˜×” ×¢×œ ××¦×‘ (×”×§×œ×“×”/×”×§×œ×˜×”) ×‘×¢×–×¨×ª session_state
    if 'input_mode' not in st.session_state:
        st.session_state.input_mode = None

    # JS to handle button clicks and set session_state
    st.markdown("""
    <script>
    const textBtn = window.parent.document.getElementById('text-btn');
    const micBtn = window.parent.document.getElementById('mic-btn');
    if (textBtn) textBtn.onclick = () => { window.parent.postMessage({type: 'setInputMode', mode: 'text'}, '*'); };
    if (micBtn) micBtn.onclick = () => { window.parent.postMessage({type: 'setInputMode', mode: 'mic'}, '*'); };
    </script>
    """, unsafe_allow_html=True)

    # Streamlit can't directly listen to JS, so use a workaround:
    input_mode = st.radio("×‘×—×¨×• ×“×¨×š ×œ×”×–×™×Ÿ:", ["×”×§×œ×“×”", "×”×§×œ×˜×”"], horizontal=True, index=0, key="input_mode_radio", label_visibility="collapsed")
    if input_mode == "×”×§×œ×“×”":
        user_input = st.text_input("××” ×ª×¨×¦×• ×©×™×”×™×” ×‘×¡×œ?", value="", key="text_input", placeholder="×”×§×œ×™×“×• ×›××Ÿ ×‘×¢×‘×¨×™×ª...")
    elif input_mode == "×”×§×œ×˜×”":
        if st.button("×”×ª×—×œ ×œ×”×§×œ×™×˜ ğŸ¤", key="record"):
            user_input = transcribe_audio()
    if example_clicked:
        user_input = example_clicked

    if user_input:
        st.markdown(f"<div class='wow-box'><b>ğŸ¯ ××” ×©×©××¢× ×•/×‘×—×¨×ª:</b> {user_input}</div>", unsafe_allow_html=True)

        # 1. ×˜×§×¡×˜ ×©×™×¨×™
        with st.spinner("ğŸ“ ×™×•×¦×¨ ×˜×§×¡×˜ ×©×™×¨×™ ×œ×¡×œ ×©×œ×š..."):
            hebrew_text = generate_hebrew_text(user_input)
        if hebrew_text:
            st.markdown(f"<div class='wow-box' style='border-color:#d72660;'><b>ğŸ“</b> {hebrew_text}</div>", unsafe_allow_html=True)

            # 2. ×ª××•× ×” ×¢× progress bar
            progress_bar = st.progress(0, text="ğŸ¨ ×™×•×¦×¨ ×ª××•× ×” ×©×œ ×”×¡×œ ×©×œ×š...")
            import time
            for percent_complete in range(1, 101, 10):
                progress_bar.progress(percent_complete, text="ğŸ¨ ×™×•×¦×¨ ×ª××•× ×” ×©×œ ×”×¡×œ ×©×œ×š...")
                time.sleep(0.03)
            image_url = generate_image(user_input)
            progress_bar.progress(100, text="âœ… ×”×ª××•× ×” ××•×›× ×”!")
            if image_url:
                st.image(image_url, caption="×”×¡×œ ×©×œ×š ×œ×‘×™×›×•×¨×™×", use_column_width=True, output_format="auto")

            # ×›×¤×ª×•×¨ ×©×™×ª×•×£
            share_text = f"×”× ×” ×”×¡×œ ×©×œ×™ ×œ×‘×™×›×•×¨×™×! {hebrew_text}"
            whatsapp_url = f"https://wa.me/?text={share_text}"
            st.markdown(f'<a href="{whatsapp_url}" target="_blank" style="font-size:1.3em; color:#25d366;">ğŸ“± ×©×ª×£ ×‘×•×•××˜×¡××¤</a>', unsafe_allow_html=True)

if __name__ == "__main__":
    # ××ª×—×•×œ ×”×’× ×¨×˜×•×¨×™×
    pollinations = PollinationsGenerator()
    # together_ai = TogetherAIGenerator()  # Commented out - file doesn't exist
    main()